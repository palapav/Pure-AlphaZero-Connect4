unit testing -> statement, boundary, path, stress

Read AlphaZero paper -> all detailed

* check on selection

# np.random.choice for root policy vector (done)

* stop illegal moves in eval mode

# cross entropy -> zero sum property

# check whether policy and chosen actions are lining up index wise

* total z value / total visits (done)

* temperature parameter -> take all probabiltiies and raise to one over temperature power
if temperature is very high -> policy very explorative

* refactor out for loops

* print board states, policy states, and values

* add regularization to loss function

* casting to double in loss function -> see if there is a better way

* need to remove reward/terminal score attribute (done -> using is_finished)

TESTING PARADIGM
- need to test at the functional level
- then piecing all the functions together to form a working program (mcts)
- then need to test single game
- then test entire train pipeline
- as abstraction gets larger -> testing needs to scale at the same time
- so we can better isolate problems and have better defined inputs and outputs

* check views versus copies

* does convert_arr need to be a static method?

# refactor Node class -> create smaller objects -> too many parameters

need to select the best move for each player at the respective depth based on player who is about to play

Why MCTS is more focused on building out current columns instead of exploring other columns

Store player who is about to move and moved placed on board in game dataset
but don't store in training data

Fix game dataset to include all training examples instead of just one training example (memory address issue potentially)

Do a detailed printing at all levels -> all levels of code should be tested


Do a detailed memory analysis at all levels

MAJOR BUG FIX -> ROOT game board being passed down from game to MCTS level using same
memory address -> we are never storing the previous boards

We are thinking it's at the list level per element -> we need to do an introspection for the elements themselves
when something looks convincing -> move onto other reasons surrounding the same problem
don't keep on forcing on the same problem

Be very careful when mutating memory addresses

check root pi policy mem addresses

need to add graph loss

need to make train_alphazero function amenable to stopping and continuing training

need to add dynamic piping losses to text files as status reports

increase number of episodes per iteration?
